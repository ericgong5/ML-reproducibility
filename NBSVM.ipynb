{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J93G8g_HvGzL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import Input, Embedding, Flatten, dot\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.datasets import load_files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import requests\n",
        "\n",
        "master_input = \"https://raw.githubusercontent.com/shagunsodhani/CNN-Sentence-Classifier/master/sample_dataset/input.txt\"\n",
        "req_input = requests.get(master_input)\n",
        "req_input = req_input.text\n",
        "input_list = req_input.splitlines()\n",
        "\n",
        "\n",
        "master_label = \"https://raw.githubusercontent.com/shagunsodhani/CNN-Sentence-Classifier/master/sample_dataset/label.txt\"\n",
        "req_label = requests.get(master_label)\n",
        "req_label = req_label.text\n",
        "label_list = req_label.splitlines()\n",
        "\n"
      ],
      "metadata": {
        "id": "AVs1mXGAzgI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos = []\n",
        "neg = []\n",
        "\n",
        "for i in range(len(label_list)):\n",
        "  if(label_list[i]== 'positive'):\n",
        "    pos.append(input_list[i])\n",
        "  else:\n",
        "    neg.append(input_list[i]) \n",
        "\n",
        "len(pos),len(neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L06xetLc1Ngc",
        "outputId": "1ed6c1f2-2a77-4c2a-caf5-2f095576c748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5331, 5331)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(pos)\n",
        "random.shuffle(neg)\n",
        "\n",
        "\n",
        "middle = 8530 / 2\n",
        "\n",
        "train_pos = []\n",
        "test_pos = []\n",
        "train_neg = []\n",
        "test_neg = []\n",
        "\n",
        "for j in range(len(pos)):\n",
        "  if j < middle:\n",
        "    train_pos.append(pos[j])\n",
        "    train_neg.append(neg[j])\n",
        "  else:\n",
        "    test_pos.append(pos[j])\n",
        "    test_neg.append(neg[j])\n",
        "\n",
        "len(train_pos),len(test_pos),len(train_neg),len(test_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jWOZ7nE2Ev1",
        "outputId": "17f4cd94-df3a-4fcf-a410-eadf0cf4e5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4265, 1066, 4265, 1066)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory called \"data\" if it doesn't exist already\n",
        "if not os.path.exists(\"data\"):\n",
        "    os.makedirs(\"data\")\n",
        "  \n",
        "if not os.path.exists(\"data/train\"):\n",
        "    os.makedirs(\"data/train\")\n",
        "\n",
        "if not os.path.exists(\"data/train/neg\"):\n",
        "    os.makedirs(\"data/train/neg\")\n",
        "\n",
        "if not os.path.exists(\"data/train/pos\"):\n",
        "    os.makedirs(\"data/train/pos\")\n",
        "\n",
        "if not os.path.exists(\"data/test\"):\n",
        "    os.makedirs(\"data/test\")\n",
        "\n",
        "if not os.path.exists(\"data/test/neg\"):\n",
        "    os.makedirs(\"data/test/neg\")\n",
        "\n",
        "if not os.path.exists(\"data/test/pos\"):\n",
        "    os.makedirs(\"data/test/pos\")"
      ],
      "metadata": {
        "id": "f0tC6pIP3tMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = 0\n",
        "\n",
        "for string in train_pos:\n",
        "  filename = str(name) + \".txt\"\n",
        "  name += 1\n",
        "  with open(\"data/train/pos/%s\" %(filename), \"w\") as f:\n",
        "        f.write(string)\n",
        "        \n",
        "for string in train_neg:\n",
        "  filename = str(name) + \".txt\"\n",
        "  name += 1\n",
        "  with open(\"data/train/neg/%s\" %(filename), \"w\") as f:\n",
        "        f.write(string)\n",
        "\n",
        "for string in test_pos:\n",
        "  filename = str(name) + \".txt\"\n",
        "  name += 1\n",
        "  with open(\"data/test/pos/%s\" %(filename), \"w\") as f:\n",
        "        f.write(string)\n",
        "\n",
        "for string in test_neg:\n",
        "  filename = str(name) + \".txt\"\n",
        "  name += 1\n",
        "  with open(\"data/test/neg/%s\" %(filename), \"w\") as f:\n",
        "        f.write(string)\n",
        "\n"
      ],
      "metadata": {
        "id": "NqrN8V374nQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_IMDB = r'data'\n",
        "def load_imdb_data(datadir):\n",
        "    # read in training and test corpora\n",
        "    categories= ['pos', 'neg']\n",
        "    train_b = load_files(datadir+'/train', shuffle=True, \n",
        "                         categories=categories)\n",
        "    test_b = load_files(datadir+'/test', shuffle=True,\n",
        "                         categories=categories)\n",
        "    train_b.data = [x.decode('utf-8') for x in train_b.data]\n",
        "    test_b.data =  [x.decode('utf-8') for x in test_b.data]\n",
        "    veczr =  CountVectorizer(ngram_range=(1,3), binary=True, \n",
        "                             token_pattern=r'\\w+',\n",
        "                             max_features=800000)\n",
        "    dtm_train = veczr.fit_transform(train_b.data)\n",
        "    dtm_test = veczr.transform(test_b.data)\n",
        "    y_train = train_b.target\n",
        "    y_test = test_b.target\n",
        "    print(\"DTM shape (training): (%s, %s)\" % (dtm_train.shape))\n",
        "    print(\"DTM shape (test): (%s, %s)\" % (dtm_train.shape))\n",
        "    num_words = len([v for k,v in veczr.vocabulary_.items()]) + 1\n",
        "    print('vocab size:%s' % (num_words))\n",
        "  \n",
        "    return (dtm_train, dtm_test), (y_train, y_test), num_words\n",
        "\n",
        "(dtm_train, dtm_test), (y_train, y_test), num_words = load_imdb_data(PATH_TO_IMDB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV3SSGOZvSPi",
        "outputId": "4591babd-4338-4abd-bc8a-2eaa76a302b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DTM shape (training): (8530, 235076)\n",
            "DTM shape (test): (8530, 235076)\n",
            "vocab size:235077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dtm2wid(dtm, maxlen):\n",
        "    x = []\n",
        "    nwds = []\n",
        "    for idx, row in enumerate(dtm):\n",
        "        seq = []\n",
        "        indices = (row.indices + 1).astype(np.int64)\n",
        "        np.append(nwds, len(indices))\n",
        "        data = (row.data).astype(np.int64)\n",
        "        count_dict = dict(zip(indices, data))\n",
        "        for k,v in count_dict.items():\n",
        "            seq.extend([k]*v)\n",
        "        num_words = len(seq)\n",
        "        nwds.append(num_words)\n",
        "        # pad up to maxlen with 0\n",
        "        if num_words < maxlen: \n",
        "            seq = np.pad(seq, (maxlen - num_words, 0),    \n",
        "                         mode='constant')\n",
        "        # truncate down to maxlen\n",
        "        else:                  \n",
        "            seq = seq[-maxlen:]\n",
        "        x.append(seq)\n",
        "    nwds = np.array(nwds)\n",
        "    print('sequence stats: avg:%s, max:%s, min:%s' % (nwds.mean(),\n",
        "                                                      nwds.max(), \n",
        "                                                      nwds.min()) )\n",
        "    return np.array(x)\n",
        "maxlen = 500\n",
        "x_train = dtm2wid(dtm_train, maxlen)\n",
        "x_test = dtm2wid(dtm_test, maxlen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCn95SuXwJlG",
        "outputId": "07d940ea-99ed-4d0b-a73b-d84bce48acbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sequence stats: avg:53.29601406799531, max:144, min:1\n",
            "sequence stats: avg:29.77016885553471, max:86, min:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pr(dtm, y, y_i):\n",
        "    p = dtm[y==y_i].sum(0)\n",
        "    return (p+1) / ((y==y_i).sum()+1)\n",
        "\n",
        "nbratios = np.log(pr(dtm_train, y_train, 1)/pr(dtm_train, \n",
        "                                               y_train, 0))\n",
        "nbratios = np.squeeze(np.asarray(nbratios))"
      ],
      "metadata": {
        "id": "4nkdBWpDwLpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(num_words, maxlen, nbratios=None):\n",
        "    # setup the embedding matrix for NB log-count ratios\n",
        "    embedding_matrix = np.zeros((num_words, 1))\n",
        "    for i in range(1, num_words): # skip 0, the padding value\n",
        "        if nbratios is not None:\n",
        "            # if log-count ratios are supplied, then it's NBSVM\n",
        "            embedding_matrix[i] = nbratios[i-1]\n",
        "        else:\n",
        "            # if log-count ratios are not supplied, \n",
        "            # this reduces to a logistic regression\n",
        "            embedding_matrix[i] = 1\n",
        "    # setup the model\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    r = Embedding(num_words, 1, input_length=maxlen, \n",
        "                  weights=[embedding_matrix], \n",
        "                  trainable=False)(inp)\n",
        "    x = Embedding(num_words, 1, input_length=maxlen, \n",
        "                  embeddings_initializer='glorot_normal')(inp)\n",
        "    x = dot([r,x], axes=1)\n",
        "    x = Flatten()(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=0.001),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "flNPKUqxwNp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model(num_words, maxlen, nbratios=nbratios)\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=50,\n",
        "          epochs=10,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUqpLOTFwPSf",
        "outputId": "0e2fc72b-a718-4dbc-e035-9abd4152b0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "171/171 [==============================] - 2s 9ms/step - loss: 0.6528 - accuracy: 0.8067 - val_loss: 0.6372 - val_accuracy: 0.7753\n",
            "Epoch 2/10\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.9751 - val_loss: 0.5984 - val_accuracy: 0.7777\n",
            "Epoch 3/10\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 0.3896 - accuracy: 0.9868 - val_loss: 0.5715 - val_accuracy: 0.7791\n",
            "Epoch 4/10\n",
            "171/171 [==============================] - 2s 9ms/step - loss: 0.3141 - accuracy: 0.9925 - val_loss: 0.5521 - val_accuracy: 0.7795\n",
            "Epoch 5/10\n",
            "171/171 [==============================] - 2s 10ms/step - loss: 0.2601 - accuracy: 0.9950 - val_loss: 0.5374 - val_accuracy: 0.7781\n",
            "Epoch 6/10\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 0.2199 - accuracy: 0.9961 - val_loss: 0.5258 - val_accuracy: 0.7786\n",
            "Epoch 7/10\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 0.1890 - accuracy: 0.9967 - val_loss: 0.5164 - val_accuracy: 0.7800\n",
            "Epoch 8/10\n",
            "171/171 [==============================] - 1s 8ms/step - loss: 0.1645 - accuracy: 0.9973 - val_loss: 0.5089 - val_accuracy: 0.7786\n",
            "Epoch 9/10\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 0.1447 - accuracy: 0.9980 - val_loss: 0.5024 - val_accuracy: 0.7800\n",
            "Epoch 10/10\n",
            "171/171 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9984 - val_loss: 0.4970 - val_accuracy: 0.7814\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc468289a50>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [16, 32, 64]\n",
        "epochs = [5, 10, 15]"
      ],
      "metadata": {
        "id": "zWj5KA3BYg3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(batch_sizes)):\n",
        "  for j in range(len(epochs)):\n",
        "    model = get_model(num_words, maxlen, nbratios=nbratios)\n",
        "    model.fit(x_train, y_train,\n",
        "          batch_size=batch_sizes[i],\n",
        "          epochs=epochs[j],\n",
        "          validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03765eR1YZhW",
        "outputId": "a92588d6-4d15-4c4e-c8d5-dfc7b83ec34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "534/534 [==============================] - 5s 7ms/step - loss: 0.6266 - accuracy: 0.8208 - val_loss: 0.6051 - val_accuracy: 0.7763\n",
            "Epoch 2/5\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.4133 - accuracy: 0.9746 - val_loss: 0.5587 - val_accuracy: 0.7758\n",
            "Epoch 3/5\n",
            "534/534 [==============================] - 4s 7ms/step - loss: 0.2875 - accuracy: 0.9900 - val_loss: 0.5317 - val_accuracy: 0.7763\n",
            "Epoch 4/5\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.2130 - accuracy: 0.9947 - val_loss: 0.5138 - val_accuracy: 0.7781\n",
            "Epoch 5/5\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.1644 - accuracy: 0.9965 - val_loss: 0.5007 - val_accuracy: 0.7805\n",
            "Epoch 1/10\n",
            "534/534 [==============================] - 4s 7ms/step - loss: 0.6265 - accuracy: 0.8161 - val_loss: 0.6048 - val_accuracy: 0.7767\n",
            "Epoch 2/10\n",
            "534/534 [==============================] - 4s 8ms/step - loss: 0.4135 - accuracy: 0.9743 - val_loss: 0.5586 - val_accuracy: 0.7758\n",
            "Epoch 3/10\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.2874 - accuracy: 0.9893 - val_loss: 0.5314 - val_accuracy: 0.7800\n",
            "Epoch 4/10\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.2129 - accuracy: 0.9946 - val_loss: 0.5135 - val_accuracy: 0.7791\n",
            "Epoch 5/10\n",
            "534/534 [==============================] - 6s 12ms/step - loss: 0.1644 - accuracy: 0.9965 - val_loss: 0.5006 - val_accuracy: 0.7819\n",
            "Epoch 6/10\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.1306 - accuracy: 0.9974 - val_loss: 0.4911 - val_accuracy: 0.7871\n",
            "Epoch 7/10\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.1058 - accuracy: 0.9984 - val_loss: 0.4838 - val_accuracy: 0.7875\n",
            "Epoch 8/10\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0871 - accuracy: 0.9987 - val_loss: 0.4780 - val_accuracy: 0.7885\n",
            "Epoch 9/10\n",
            "534/534 [==============================] - 4s 8ms/step - loss: 0.0725 - accuracy: 0.9991 - val_loss: 0.4736 - val_accuracy: 0.7871\n",
            "Epoch 10/10\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0609 - accuracy: 0.9993 - val_loss: 0.4703 - val_accuracy: 0.7889\n",
            "Epoch 1/15\n",
            "534/534 [==============================] - 6s 9ms/step - loss: 0.6269 - accuracy: 0.8210 - val_loss: 0.6050 - val_accuracy: 0.7758\n",
            "Epoch 2/15\n",
            "534/534 [==============================] - 7s 13ms/step - loss: 0.4136 - accuracy: 0.9747 - val_loss: 0.5586 - val_accuracy: 0.7749\n",
            "Epoch 3/15\n",
            "534/534 [==============================] - 6s 11ms/step - loss: 0.2873 - accuracy: 0.9902 - val_loss: 0.5312 - val_accuracy: 0.7772\n",
            "Epoch 4/15\n",
            "534/534 [==============================] - 5s 10ms/step - loss: 0.2129 - accuracy: 0.9948 - val_loss: 0.5133 - val_accuracy: 0.7772\n",
            "Epoch 5/15\n",
            "534/534 [==============================] - 6s 11ms/step - loss: 0.1643 - accuracy: 0.9967 - val_loss: 0.5006 - val_accuracy: 0.7795\n",
            "Epoch 6/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.1305 - accuracy: 0.9977 - val_loss: 0.4910 - val_accuracy: 0.7847\n",
            "Epoch 7/15\n",
            "534/534 [==============================] - 4s 7ms/step - loss: 0.1058 - accuracy: 0.9980 - val_loss: 0.4836 - val_accuracy: 0.7880\n",
            "Epoch 8/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0870 - accuracy: 0.9986 - val_loss: 0.4779 - val_accuracy: 0.7875\n",
            "Epoch 9/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0724 - accuracy: 0.9991 - val_loss: 0.4734 - val_accuracy: 0.7875\n",
            "Epoch 10/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0609 - accuracy: 0.9992 - val_loss: 0.4700 - val_accuracy: 0.7871\n",
            "Epoch 11/15\n",
            "534/534 [==============================] - 4s 7ms/step - loss: 0.0516 - accuracy: 0.9994 - val_loss: 0.4677 - val_accuracy: 0.7889\n",
            "Epoch 12/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0440 - accuracy: 0.9994 - val_loss: 0.4659 - val_accuracy: 0.7894\n",
            "Epoch 13/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0378 - accuracy: 0.9995 - val_loss: 0.4649 - val_accuracy: 0.7885\n",
            "Epoch 14/15\n",
            "534/534 [==============================] - 3s 6ms/step - loss: 0.0326 - accuracy: 0.9995 - val_loss: 0.4645 - val_accuracy: 0.7885\n",
            "Epoch 15/15\n",
            "534/534 [==============================] - 4s 7ms/step - loss: 0.0283 - accuracy: 0.9998 - val_loss: 0.4647 - val_accuracy: 0.7847\n",
            "Epoch 1/5\n",
            "267/267 [==============================] - 3s 11ms/step - loss: 0.6432 - accuracy: 0.8172 - val_loss: 0.6250 - val_accuracy: 0.7716\n",
            "Epoch 2/5\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.4672 - accuracy: 0.9751 - val_loss: 0.5827 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.3495 - accuracy: 0.9887 - val_loss: 0.5552 - val_accuracy: 0.7791\n",
            "Epoch 4/5\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.2733 - accuracy: 0.9936 - val_loss: 0.5363 - val_accuracy: 0.7772\n",
            "Epoch 5/5\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.2209 - accuracy: 0.9957 - val_loss: 0.5221 - val_accuracy: 0.7800\n",
            "Epoch 1/10\n",
            "267/267 [==============================] - 3s 8ms/step - loss: 0.6435 - accuracy: 0.8193 - val_loss: 0.6257 - val_accuracy: 0.7725\n",
            "Epoch 2/10\n",
            "267/267 [==============================] - 3s 10ms/step - loss: 0.4676 - accuracy: 0.9732 - val_loss: 0.5831 - val_accuracy: 0.7739\n",
            "Epoch 3/10\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.3497 - accuracy: 0.9892 - val_loss: 0.5561 - val_accuracy: 0.7772\n",
            "Epoch 4/10\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.2735 - accuracy: 0.9932 - val_loss: 0.5369 - val_accuracy: 0.7786\n",
            "Epoch 5/10\n",
            "267/267 [==============================] - 2s 9ms/step - loss: 0.2210 - accuracy: 0.9953 - val_loss: 0.5228 - val_accuracy: 0.7777\n",
            "Epoch 6/10\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.1830 - accuracy: 0.9962 - val_loss: 0.5119 - val_accuracy: 0.7800\n",
            "Epoch 7/10\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.1543 - accuracy: 0.9975 - val_loss: 0.5033 - val_accuracy: 0.7828\n",
            "Epoch 8/10\n",
            "267/267 [==============================] - 4s 13ms/step - loss: 0.1320 - accuracy: 0.9980 - val_loss: 0.4963 - val_accuracy: 0.7814\n",
            "Epoch 9/10\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.1142 - accuracy: 0.9986 - val_loss: 0.4906 - val_accuracy: 0.7828\n",
            "Epoch 10/10\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.0997 - accuracy: 0.9987 - val_loss: 0.4857 - val_accuracy: 0.7838\n",
            "Epoch 1/15\n",
            "267/267 [==============================] - 3s 7ms/step - loss: 0.6437 - accuracy: 0.8165 - val_loss: 0.6258 - val_accuracy: 0.7739\n",
            "Epoch 2/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.4677 - accuracy: 0.9748 - val_loss: 0.5832 - val_accuracy: 0.7763\n",
            "Epoch 3/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.3498 - accuracy: 0.9882 - val_loss: 0.5557 - val_accuracy: 0.7781\n",
            "Epoch 4/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.2735 - accuracy: 0.9933 - val_loss: 0.5366 - val_accuracy: 0.7772\n",
            "Epoch 5/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.2210 - accuracy: 0.9953 - val_loss: 0.5224 - val_accuracy: 0.7800\n",
            "Epoch 6/15\n",
            "267/267 [==============================] - 3s 9ms/step - loss: 0.1829 - accuracy: 0.9961 - val_loss: 0.5115 - val_accuracy: 0.7805\n",
            "Epoch 7/15\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.1542 - accuracy: 0.9972 - val_loss: 0.5029 - val_accuracy: 0.7805\n",
            "Epoch 8/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.1319 - accuracy: 0.9980 - val_loss: 0.4959 - val_accuracy: 0.7819\n",
            "Epoch 9/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.1141 - accuracy: 0.9984 - val_loss: 0.4901 - val_accuracy: 0.7824\n",
            "Epoch 10/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.0996 - accuracy: 0.9987 - val_loss: 0.4852 - val_accuracy: 0.7852\n",
            "Epoch 11/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.0876 - accuracy: 0.9988 - val_loss: 0.4811 - val_accuracy: 0.7847\n",
            "Epoch 12/15\n",
            "267/267 [==============================] - 2s 8ms/step - loss: 0.0776 - accuracy: 0.9992 - val_loss: 0.4777 - val_accuracy: 0.7861\n",
            "Epoch 13/15\n",
            "267/267 [==============================] - 3s 9ms/step - loss: 0.0690 - accuracy: 0.9994 - val_loss: 0.4748 - val_accuracy: 0.7847\n",
            "Epoch 14/15\n",
            "267/267 [==============================] - 2s 7ms/step - loss: 0.0617 - accuracy: 0.9994 - val_loss: 0.4723 - val_accuracy: 0.7856\n",
            "Epoch 15/15\n",
            "267/267 [==============================] - 2s 6ms/step - loss: 0.0554 - accuracy: 0.9994 - val_loss: 0.4703 - val_accuracy: 0.7852\n",
            "Epoch 1/5\n",
            "134/134 [==============================] - 2s 10ms/step - loss: 0.6575 - accuracy: 0.8048 - val_loss: 0.6427 - val_accuracy: 0.7772\n",
            "Epoch 2/5\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.5162 - accuracy: 0.9758 - val_loss: 0.6060 - val_accuracy: 0.7805\n",
            "Epoch 3/5\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.4112 - accuracy: 0.9877 - val_loss: 0.5799 - val_accuracy: 0.7767\n",
            "Epoch 4/5\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.9918 - val_loss: 0.5607 - val_accuracy: 0.7786\n",
            "Epoch 5/5\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.2826 - accuracy: 0.9948 - val_loss: 0.5457 - val_accuracy: 0.7777\n",
            "Epoch 1/10\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.6571 - accuracy: 0.8079 - val_loss: 0.6426 - val_accuracy: 0.7772\n",
            "Epoch 2/10\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.5159 - accuracy: 0.9743 - val_loss: 0.6058 - val_accuracy: 0.7791\n",
            "Epoch 3/10\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.4111 - accuracy: 0.9873 - val_loss: 0.5799 - val_accuracy: 0.7800\n",
            "Epoch 4/10\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.3368 - accuracy: 0.9921 - val_loss: 0.5606 - val_accuracy: 0.7786\n",
            "Epoch 5/10\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.2825 - accuracy: 0.9947 - val_loss: 0.5457 - val_accuracy: 0.7795\n",
            "Epoch 6/10\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.2414 - accuracy: 0.9957 - val_loss: 0.5341 - val_accuracy: 0.7777\n",
            "Epoch 7/10\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.2094 - accuracy: 0.9964 - val_loss: 0.5244 - val_accuracy: 0.7777\n",
            "Epoch 8/10\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1838 - accuracy: 0.9970 - val_loss: 0.5165 - val_accuracy: 0.7781\n",
            "Epoch 9/10\n",
            "134/134 [==============================] - 1s 11ms/step - loss: 0.1629 - accuracy: 0.9975 - val_loss: 0.5097 - val_accuracy: 0.7800\n",
            "Epoch 10/10\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.1456 - accuracy: 0.9981 - val_loss: 0.5039 - val_accuracy: 0.7805\n",
            "Epoch 1/15\n",
            "134/134 [==============================] - 2s 10ms/step - loss: 0.6578 - accuracy: 0.8074 - val_loss: 0.6429 - val_accuracy: 0.7744\n",
            "Epoch 2/15\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.5164 - accuracy: 0.9767 - val_loss: 0.6065 - val_accuracy: 0.7749\n",
            "Epoch 3/15\n",
            "134/134 [==============================] - 1s 10ms/step - loss: 0.4112 - accuracy: 0.9877 - val_loss: 0.5802 - val_accuracy: 0.7767\n",
            "Epoch 4/15\n",
            "134/134 [==============================] - 2s 12ms/step - loss: 0.3370 - accuracy: 0.9912 - val_loss: 0.5610 - val_accuracy: 0.7781\n",
            "Epoch 5/15\n",
            "134/134 [==============================] - 1s 10ms/step - loss: 0.2826 - accuracy: 0.9945 - val_loss: 0.5460 - val_accuracy: 0.7777\n",
            "Epoch 6/15\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.2415 - accuracy: 0.9958 - val_loss: 0.5341 - val_accuracy: 0.7786\n",
            "Epoch 7/15\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.2094 - accuracy: 0.9966 - val_loss: 0.5246 - val_accuracy: 0.7795\n",
            "Epoch 8/15\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1838 - accuracy: 0.9970 - val_loss: 0.5165 - val_accuracy: 0.7800\n",
            "Epoch 9/15\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1629 - accuracy: 0.9977 - val_loss: 0.5097 - val_accuracy: 0.7800\n",
            "Epoch 10/15\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1456 - accuracy: 0.9980 - val_loss: 0.5040 - val_accuracy: 0.7795\n",
            "Epoch 11/15\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.1311 - accuracy: 0.9981 - val_loss: 0.4990 - val_accuracy: 0.7791\n",
            "Epoch 12/15\n",
            "134/134 [==============================] - 1s 8ms/step - loss: 0.1187 - accuracy: 0.9986 - val_loss: 0.4946 - val_accuracy: 0.7814\n",
            "Epoch 13/15\n",
            "134/134 [==============================] - 1s 9ms/step - loss: 0.1080 - accuracy: 0.9987 - val_loss: 0.4908 - val_accuracy: 0.7828\n",
            "Epoch 14/15\n",
            "134/134 [==============================] - 2s 11ms/step - loss: 0.0987 - accuracy: 0.9989 - val_loss: 0.4874 - val_accuracy: 0.7852\n",
            "Epoch 15/15\n",
            "134/134 [==============================] - 1s 11ms/step - loss: 0.0906 - accuracy: 0.9989 - val_loss: 0.4845 - val_accuracy: 0.7856\n"
          ]
        }
      ]
    }
  ]
}